{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset de treino\n",
    "df_treino = pd.read_csv('data/dados_treino.csv')\n",
    "\n",
    "# Carregando o dataset de treino final\n",
    "df_treino_final = pd.read_csv('data/dados_treino_final.csv')\n",
    "\n",
    "# Carregando o dataset de validação\n",
    "df_valid = pd.read_csv('data/dados_valid.csv')\n",
    "\n",
    "# Carregando o dataset de teste\n",
    "df_teste = pd.read_csv('data/dados_teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os nomes das colunas de entrada\n",
    "with open('data/colunas_entrada.sav', 'rb') as file:\n",
    "    colunas_entrada = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara a Matriz X\n",
    "X_treino = df_treino_final[colunas_entrada].values\n",
    "X_valid = df_valid[colunas_entrada].values\n",
    "X_teste = df_teste[colunas_entrada].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara a Matriz Y\n",
    "y_treino = df_treino_final['LABEL_TARGET'].values\n",
    "y_valid = df_valid['LABEL_TARGET'].values\n",
    "y_teste = df_teste['LABEL_TARGET'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos dados de treino: (3228, 178) (3228,)\n",
      "Shape dos dados de validação: (1725, 178) (1725,)\n",
      "Shape dos dados de teste: (1725, 178) (1725,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape dos dados de treino:', X_treino.shape, y_treino.shape)\n",
    "print('Shape dos dados de validação:', X_valid.shape, y_valid.shape)\n",
    "print('Shape dos dados de teste:', X_teste.shape, y_teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padronização dos Dados\n",
    "\n",
    "A padronização é uma técnica de pré-processamento de dados usada em Machine Learning para transformar as variáveis de entrada (features) de modo que tenham média zero e desvio padrão igual a um. Esse processo é realizado subtraindo a média e dividindo pelo desvio padrão de cada variável. A padronização é importante por várias razões:\n",
    "\n",
    "\n",
    "1. Uniformiza a Escala das Variáveis\n",
    "\n",
    "Em muitos conjuntos de dados, as variáveis podem operar em escalas muito diferentes. Por exemplo, uma variável pode variar de 0 a 1, enquanto outra pode variar de 0 a 1000. Modelos de Machine Learning que dependem da distância entre os pontos de dados, como K-Means, K-NN (K-Nearest Neighbors), e SVM (Support Vector Machines), podem ser afetados negativamente se as variáveis não estiverem na mesma escala, pois dão mais peso às variáveis com maior magnitude.\n",
    "\n",
    "\n",
    "\n",
    "2. Acelera a Convergência em Algoritmos de Otimização\n",
    "\n",
    "Muitos modelos de Machine Learning, especialmente aqueles baseados em métodos de gradiente descendente (como redes neurais e regressão logística), se beneficiam da padronização porque isso facilita a convergência do algoritmo de otimização. Sem padronização, o espaço de busca pode ser distorcido, fazendo com que o algoritmo de otimização leve mais tempo para encontrar o mínimo global.\n",
    "\n",
    "\n",
    "\n",
    "3. Requisito para Alguns Modelos\n",
    "\n",
    "Alguns algoritmos de Machine Learning assumem explicitamente que os dados estão centrados em torno de zero e têm variação uniforme. Por exemplo, algoritmos que utilizam regularização, como Ridge e Lasso na regressão linear, podem ter seu desempenho prejudicado se os dados não forem padronizados, pois a regularização penaliza a magnitude dos coeficientes associados a cada variável.\n",
    "\n",
    "\n",
    "\n",
    "4. Melhora a Interpretabilidade dos Modelos\n",
    "\n",
    "Quando os dados são padronizados, torna-se mais fácil interpretar a importância das variáveis (features) em alguns modelos, como a regressão linear, onde os coeficientes representam a mudança esperada na variável de saída para uma mudança de uma unidade na variável de entrada, assumindo que todas as outras variáveis permanecem constantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crio o objeto\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Faço o fit\n",
    "scaler.fit(X_treino)\n",
    "\n",
    "# Salva o objeto em disco e carrega para usarmos adiante\n",
    "scalerfile = 'data/scaler.sav'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))\n",
    "\n",
    "# Carrega o scaler (padronizador)\n",
    "scaler = pickle.load(open(scalerfile, 'rb'))\n",
    "\n",
    "# Aplica a padronização em nossas matrizes de dados\n",
    "X_treino_tf = scaler.transform(X_treino)\n",
    "X_valid_tf = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem Preditiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a especificidade\n",
    "def dsa_calcula_especificidade(y_actual, y_pred, thresh):\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) / sum(y_actual == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A especificidade é uma métrica usada para avaliar o desempenho de um modelo de classificação, especialmente em problemas de classificação binária. Ela mede a proporção de verdadeiros negativos (TN) em relação ao total de negativos reais, ou seja, a capacidade do modelo de identificar corretamente as instâncias negativas.\n",
    "\n",
    "Aqui está o que cada parte significa:\n",
    "\n",
    "**y_pred < thresh**: Esta é uma condição que verifica se a previsão do modelo (y_pred) é menor que um determinado limiar (thresh). Se o modelo for de classificação binária, esse limiar geralmente é 0.5, mas pode ser ajustado de acordo com as necessidades específicas do problema. Essa condição retorna um vetor booleano, onde cada elemento é True se a previsão for menor que o limiar (indicando uma previsão de classe negativa) e False caso contrário.\n",
    "\n",
    "**y_actual == 0**: Esta é uma condição que verifica quais elementos do vetor de rótulos reais (y_actual) são iguais a 0, ou seja, pertencem à classe negativa. Isso também retorna um vetor booleano.\n",
    "\n",
    "**(y_pred < thresh) & (y_actual == 0)**: Este é o operador lógico \"e\" aplicado entre os dois vetores booleanos anteriores. Ele retorna um novo vetor booleano, onde cada elemento é True apenas se ambas as condições forem verdadeiras para esse elemento, ou seja, se a previsão for negativa e o rótulo real também for negativo. Isso representa os verdadeiros negativos (TN).\n",
    "\n",
    "**sum((y_pred < thresh) & (y_actual == 0))**: Esta é a soma dos valores True no vetor booleano resultante, que é equivalente ao número de verdadeiros negativos (TN).\n",
    "\n",
    "**sum(y_actual == 0)**: Esta é a soma dos valores True no vetor booleano que representa os rótulos reais negativos, que é equivalente ao número total de instâncias negativas reais (TN + FP).\n",
    "\n",
    "**sum((y_pred < thresh) & (y_actual == 0)) / sum(y_actual == 0)**: Esta é a razão entre o número de verdadeiros negativos (TN) e o número total de instâncias negativas reais (TN + FP), que é a definição de especificidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar relatório de métricas\n",
    "def dsa_print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = dsa_calcula_especificidade(y_actual, y_pred, thresh)\n",
    "    \n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('Acurácia:%.3f'%accuracy)\n",
    "    print('Recall:%.3f'%recall)\n",
    "    print('Precisão:%.3f'%precision)\n",
    "    print('Especificidade:%.3f'%specificity)\n",
    "    print(' ')\n",
    "    \n",
    "    return auc, accuracy, recall, precision, specificity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão 1 do Modelo - Regressão Logística (Sem Otimização de Hiperparâmetros)\n",
    "\n",
    "O algoritmo de Regressão Logística é um método estatístico para prever a probabilidade de uma variável dependente binária, com base em uma ou mais variáveis independentes. É amplamente usado para classificação binária, como prever se um e-mail é spam ou não spam, ou se um tumor é maligno ou benigno. A Regressão Logística aplica a função logística (ou sigmoidal) às previsões para transformar valores lineares em probabilidades que variam entre 0 e 1. Aqui está uma descrição passo a passo do algoritmo:\n",
    "\n",
    "\n",
    "**Modelagem da Probabilidade:** A probabilidade de que a variável dependente seja igual a uma das categorias é modelada como uma função das variáveis independentes. \n",
    "\n",
    "\n",
    "**Estimação dos Coeficientes:** Os coeficientes (b) são estimados durante o treinamento do modelo. Isso geralmente é feito usando o método da máxima verossimilhança, que busca encontrar os valores de b que maximizam a probabilidade de observar os dados amostrais. Esse processo pode ser realizado através de técnicas de otimização como o método do gradiente descendente.\n",
    "\n",
    "\n",
    "**Previsão:** Com os coeficientes estimados, o modelo pode fazer previsões sobre novos dados. A combinação linear dos coeficientes estimados e os valores das variáveis independentes é passada pela função logística para prever a probabilidade de a variável dependente ser 1. Se essa probabilidade for maior que um limiar específico (geralmente 0,5), a previsão é 1; caso contrário, é 0.\n",
    "\n",
    "\n",
    "**Avaliação do Modelo:** A performance do modelo de Regressão Logística é geralmente avaliada usando métricas como a acurácia, a área sob a curva ROC (AUC-ROC), a precisão, o recall e a pontuação F1. Essas métricas ajudam a entender como o modelo performa tanto em termos de sensibilidade quanto de especificidade.\n",
    "\n",
    "\n",
    "**Regularização:** Para evitar o overfitting, especialmente quando o número de observações é pequeno ou quando o modelo é muito complexo (com muitas variáveis independentes), técnicas de regularização como L1 (Lasso) e L2 (Ridge) podem ser aplicadas. A regularização penaliza os coeficientes grandes, reduzindo a complexidade do modelo.\n",
    "\n",
    "A Regressão Logística é eficaz para problemas de classificação binária e pode ser estendida para classificação multiclasse como a Regressão Logística Multinomial.\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Regressão Logística (Sem Otimização de Hiperparâmetros)\n",
      "\n",
      "Treinamento:\n",
      "\n",
      "AUC:0.627\n",
      "Acurácia:0.660\n",
      "Recall:0.531\n",
      "Precisão:0.717\n",
      "Especificidade:0.790\n",
      " \n",
      "Validação:\n",
      "\n",
      "AUC:0.525\n",
      "Acurácia:0.696\n",
      "Recall:0.471\n",
      "Precisão:0.325\n",
      "Especificidade:0.752\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Construção do modelo\n",
    "\n",
    "# Cria o classificador (objeto)\n",
    "lr1 = LogisticRegression()\n",
    "\n",
    "# Treina e cria o modelo\n",
    "modelo_v1 = lr1.fit(X_treino_tf, y_treino)\n",
    "\n",
    "# Previsões \n",
    "y_train_preds = modelo_v1.predict_proba(X_treino_tf)[:,1]\n",
    "y_valid_preds = modelo_v1.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Modelo de Regressão Logística (Sem Otimização de Hiperparâmetros)\\n')\n",
    "\n",
    "print('Treinamento:\\n')\n",
    "lr1_train_auc, lr1_train_accuracy, lr1_train_recall, lr1_train_precision, lr1_train_specificity = dsa_print_report(y_treino, \n",
    "                                                                                                                   y_train_preds, \n",
    "                                                                                                                   thresh)\n",
    "\n",
    "print('Validação:\\n')\n",
    "lr1_valid_auc, lr1_valid_accuracy, lr1_valid_recall, lr1_valid_precision, lr1_valid_specificity = dsa_print_report(y_valid, \n",
    "                                                                                                                   y_valid_preds, \n",
    "                                                                                                                   thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão 2 do Modelo - Regressão Logística (Com Otimização de Hiperparâmetros)\n",
    "\n",
    "O algoritmo de Regressão Logística é um método estatístico para prever a probabilidade de uma variável dependente binária, com base em uma ou mais variáveis independentes. É amplamente usado para classificação binária, como prever se um e-mail é spam ou não spam, ou se um tumor é maligno ou benigno. A Regressão Logística aplica a função logística (ou sigmoidal) às previsões para transformar valores lineares em probabilidades que variam entre 0 e 1. Aqui está uma descrição passo a passo do algoritmo:\n",
    "\n",
    "**Modelagem da Probabilidade:** A probabilidade de que a variável dependente seja igual a uma das categorias é modelada como uma função das variáveis independentes. \n",
    "\n",
    "\n",
    "**Estimação dos Coeficientes:** Os coeficientes (b) são estimados durante o treinamento do modelo. Isso geralmente é feito usando o método da máxima verossimilhança, que busca encontrar os valores de b que maximizam a probabilidade de observar os dados amostrais. Esse processo pode ser realizado através de técnicas de otimização como o método do gradiente descendente.\n",
    "\n",
    "**Previsão:** Com os coeficientes estimados, o modelo pode fazer previsões sobre novos dados. A combinação linear dos coeficientes estimados e os valores das variáveis independentes é passada pela função logística para prever a probabilidade de a variável dependente ser 1. Se essa probabilidade for maior que um limiar específico (geralmente 0,5), a previsão é 1; caso contrário, é 0.\n",
    "\n",
    "**Avaliação do Modelo:** A performance do modelo de Regressão Logística é geralmente avaliada usando métricas como a acurácia, a área sob a curva ROC (AUC-ROC), a precisão, o recall e a pontuação F1. Essas métricas ajudam a entender como o modelo performa tanto em termos de sensibilidade quanto de especificidade.\n",
    "\n",
    "**Regularização:** Para evitar o overfitting, especialmente quando o número de observações é pequeno ou quando o modelo é muito complexo (com muitas variáveis independentes), técnicas de regularização como L1 (Lasso) e L2 (Ridge) podem ser aplicadas. A regularização penaliza os coeficientes grandes, reduzindo a complexidade do modelo.\n",
    "\n",
    "A Regressão Logística é eficaz para problemas de classificação binária e pode ser estendida para classificação multiclasse como a Regressão Logística Multinomial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Regressão Logística (Com Otimização de Hiperparâmetros)\n",
      "\n",
      "Treinamento:\n",
      "\n",
      "AUC:0.630\n",
      "Acurácia:0.663\n",
      "Recall:0.532\n",
      "Precisão:0.720\n",
      "Especificidade:0.794\n",
      " \n",
      "Validação:\n",
      "\n",
      "AUC:0.525\n",
      "Acurácia:0.701\n",
      "Recall:0.460\n",
      "Precisão:0.328\n",
      "Especificidade:0.762\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Construção do modelo\n",
    "\n",
    "# Cria o classificador (objeto)\n",
    "lr2 = LogisticRegression(random_state = 142, solver = 'liblinear')\n",
    "\n",
    "# Treina e cria o modelo\n",
    "modelo_v2 = lr2.fit(X_treino_tf, y_treino)\n",
    "\n",
    "# Previsões \n",
    "y_train_preds = modelo_v2.predict_proba(X_treino_tf)[:,1]\n",
    "y_valid_preds = modelo_v2.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Modelo de Regressão Logística (Com Otimização de Hiperparâmetros)\\n')\n",
    "\n",
    "print('Treinamento:\\n')\n",
    "lr2_train_auc, lr2_train_accuracy, lr2_train_recall, lr2_train_precision, lr2_train_specificity = dsa_print_report(y_treino, \n",
    "                                                                                                                   y_train_preds, \n",
    "                                                                                                                   thresh)\n",
    "\n",
    "print('Validação:\\n')\n",
    "lr2_valid_auc, lr2_valid_accuracy, lr2_valid_recall, lr2_valid_precision, lr2_valid_specificity = dsa_print_report(y_valid, \n",
    "                                                                                                                   y_valid_preds, \n",
    "                                                                                                                   thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão 3 do Modelo - Naive Bayes\n",
    "\n",
    "O algoritmo Naive Bayes é um método de classificação baseado no teorema de Bayes, com a \"ingenuidade\" de assumir independência entre os preditores. Em outras palavras, presume-se que a presença ou ausência de uma característica particular em uma classe é independente da presença ou ausência de qualquer outra característica. Esse algoritmo é especialmente adequado para grandes volumes de dados e é eficaz em tarefas de classificação de texto, como filtragem de spam e análise de sentimentos.\n",
    "\n",
    "Funcionamento Básico do Algoritmo Naive Bayes:\n",
    "\n",
    "**Modelagem da Probabilidade:** O primeiro passo é calcular a probabilidade de cada classe no conjunto de treinamento, conhecida como probabilidade a priori. Em seguida, calcula-se a probabilidade condicional de cada característica dada cada classe.\n",
    "\n",
    "**Aplicação do Teorema de Bayes:** Quando uma nova instância precisa ser classificada, o algoritmo aplica o teorema de Bayes para calcular a probabilidade posterior de cada classe, dada a instância. O teorema de Bayes é uma forma de calcular a probabilidade de uma hipótese com base no conhecimento prévio e na evidência atual.\n",
    "\n",
    "**Independência Condicional:** A \"ingenuidade\" do algoritmo vem da suposição de independência entre as características. Isso significa que a presença de uma característica em uma classe não está relacionada à presença de outra característica. Essa suposição simplifica os cálculos, permitindo que o produto das probabilidades individuais das características seja usado para calcular a probabilidade total.\n",
    "\n",
    "**Classificação:** Para cada classe, o algoritmo calcula o produto da probabilidade a priori da classe e as probabilidades condicionais de cada característica dada essa classe. A classe com a maior probabilidade posterior (calculada a partir do teorema de Bayes) é escolhida como a classificação para a instância.\n",
    "\n",
    "Existem diferentes variações do Naive Bayes, dependendo da distribuição dos dados:\n",
    "\n",
    "* Gaussian Naive Bayes: Usado quando as características são contínuas e assumem uma distribuição normal.\n",
    "* Multinomial Naive Bayes: Frequentemente usado em classificação de documentos/textos, onde as características são as contagens ou frequências de ocorrência das palavras.\n",
    "* Bernoulli Naive Bayes: Usado quando as características são variáveis binárias, indicando a presença ou ausência de uma característica.\n",
    "\n",
    "**Vantagens:**\n",
    "* Simplicidade e rapidez na previsão de classes.\n",
    "* Funciona bem com um grande número de características.\n",
    "* Desempenho comparativamente bom em casos onde a suposição de independência se mantém.\n",
    "  \n",
    "**Desvantagens:**\n",
    "* A suposição de independência entre as características é muitas vezes irrealista, o que pode afetar o desempenho em algumas tarefas.\n",
    "* Pode ser superado por outros algoritmos quando a relação entre as características é importante para a classificação.\n",
    "\n",
    "Apesar de suas limitações, o Naive Bayes continua sendo uma escolha popular devido à sua eficiência e facilidade de interpretação.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Naive Bayes:\n",
      "\n",
      "Treinamento:\n",
      "\n",
      "AUC:0.983\n",
      "Acurácia:0.927\n",
      "Recall:0.884\n",
      "Precisão:0.967\n",
      "Especificidade:0.970\n",
      " \n",
      "Validação:\n",
      "\n",
      "AUC:0.984\n",
      "Acurácia:0.955\n",
      "Recall:0.865\n",
      "Precisão:0.909\n",
      "Especificidade:0.978\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Construção do modelo\n",
    "\n",
    "# Cria o classificador (objeto)\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Treina e cria o modelo\n",
    "modelo_v3 = nb.fit(X_treino_tf, y_treino)\n",
    "\n",
    "# Previsões\n",
    "y_train_preds = modelo_v3.predict_proba(X_treino_tf)[:,1]\n",
    "y_valid_preds = modelo_v3.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Modelo Naive Bayes:\\n')\n",
    "\n",
    "print('Treinamento:\\n')\n",
    "nb_train_auc, nb_train_accuracy, nb_train_recall, nb_train_precision, nb_train_specificity = dsa_print_report(y_treino, \n",
    "                                                                                                              y_train_preds, \n",
    "                                                                                                              thresh)\n",
    "\n",
    "print('Validação:\\n')\n",
    "nb_valid_auc, nb_valid_accuracy, nb_valid_recall, nb_valid_precision, nb_valid_specificity = dsa_print_report(y_valid, \n",
    "                                                                                                              y_valid_preds, \n",
    "                                                                                                              thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão 4 do Modelo - XGBoost (Xtreme Gradient Boosting Classifier)\n",
    "\n",
    "O XGBoost (eXtreme Gradient Boosting) é um algoritmo de aprendizado supervisionado que é amplamente utilizado para problemas de regressão e classificação. É uma implementação otimizada do método de boosting de gradiente, projetada para ser altamente eficiente e flexível. O XGBoost ganhou popularidade por sua velocidade e desempenho em competições de Ciência de Dados, como as hospedadas no Kaggle. Como Funciona o XGBoost:\n",
    "\n",
    "**Modelo de Árvore de Decisão:** O XGBoost constrói modelos sequenciais usando árvores de decisão. Cada nova árvore é criada para corrigir os erros (resíduos) deixados pelas árvores anteriores.\n",
    "\n",
    "**Boosting de Gradiente:** A ideia central do boosting de gradiente é combinar muitos modelos fracos (geralmente árvores de decisão) para criar um modelo forte. O \"gradiente\" no nome se refere ao uso do gradiente descendente para minimizar a função de perda ao adicionar novas árvores.\n",
    "\n",
    "**Otimização Regularizada:** O XGBoost inclui um termo de regularização na função de perda, que ajuda a controlar a complexidade do modelo. Isso reduz o overfitting e melhora a capacidade de generalização do modelo.\n",
    "\n",
    "**Técnicas de Otimização:** Utiliza várias técnicas de otimização para melhorar a eficiência e o desempenho, como:\n",
    "\n",
    "**Pruning de árvores (poda):** Para evitar o crescimento desnecessário de árvores, o XGBoost usa uma estratégia de poda baseada na ganância. Se a adição de um novo nó não resulta em melhoria significativa, a expansão é parada.\n",
    "Tratamento de valores ausentes: O XGBoost pode automaticamente aprender a melhor maneira de lidar com valores ausentes durante o treinamento.\n",
    "Paralelismo e Escalabilidade: Capaz de utilizar múltiplos núcleos de CPU durante o treinamento e escalar para sistemas distribuídos de computação.\n",
    "Ajuste de Hiperparâmetros: O desempenho do XGBoost pode ser significativamente afetado pelo ajuste de hiperparâmetros, incluindo a taxa de aprendizado, o número máximo de árvores, a profundidade de cada árvore e os parâmetros de regularização, entre outros.\n",
    "\n",
    "\n",
    "**Vantagens**\n",
    "* Alto Desempenho, frequentemente supera outros algoritmos de aprendizado de máquina em tarefas de classificação e regressão.\n",
    "* Flexibilidade, pode ser usado para problemas de regressão, classificação, ranking e muitos outros tipos de aprendizado de máquina.\n",
    "* Portabilidade, disponível em várias linguagens de programação e pode ser executado em diversas plataformas.\n",
    "* Facilidade de Uso, vem com uma variedade de parâmentos ajustáveis que podem ser afinados para obter o melhor desempenho em um determinado problema.\n",
    "\n",
    "**Desvantagens**\n",
    "* Complexidade, ajustar todos os seus hiperparâmetos pode ser uma tarefa desafiadora e demorada.\n",
    "* Overfitting: Apesar da regularização, modelos muito complexos podem ainda assim sofrer de overfitting, especialmente em dados com ruído\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Xtreme Gradient Boosting Classifier:\n",
      "\n",
      "Treinamento:\n",
      "\n",
      "AUC:1.000\n",
      "Acurácia:1.000\n",
      "Recall:1.000\n",
      "Precisão:1.000\n",
      "Especificidade:1.000\n",
      " \n",
      "Validação:\n",
      "\n",
      "AUC:0.993\n",
      "Acurácia:0.967\n",
      "Recall:0.940\n",
      "Precisão:0.901\n",
      "Especificidade:0.974\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Construção do modelo (Ensemble)\n",
    "\n",
    "# Cria o classificador\n",
    "xgbc = XGBClassifier()\n",
    "\n",
    "# Treina e cria o modelo\n",
    "modelo_v4 = xgbc.fit(X_treino_tf, y_treino)\n",
    "\n",
    "# Previsões\n",
    "y_train_preds = modelo_v4.predict_proba(X_treino_tf)[:,1]\n",
    "y_valid_preds = modelo_v4.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Modelo Xtreme Gradient Boosting Classifier:\\n')\n",
    "\n",
    "print('Treinamento:\\n')\n",
    "xgbc_train_auc, xgbc_train_accuracy, xgbc_train_recall, xgbc_train_precision, xgbc_train_specificity = dsa_print_report(y_treino, \n",
    "                                                                                                                        y_train_preds, \n",
    "                                                                                                                        thresh)\n",
    "\n",
    "print('Validação:\\n')\n",
    "xgbc_valid_auc, xgbc_valid_accuracy, xgbc_valid_recall, xgbc_valid_precision, xgbc_valid_specificity = dsa_print_report(y_valid, \n",
    "                                                                                                                        y_valid_preds, \n",
    "                                                                                                                        thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versão 5 do Modelo - RandomForest\n",
    "\n",
    "O algoritmo RandomForest é um método de aprendizado de máquina para classificação, regressão e outras tarefas, que opera construindo um conjunto de árvores de decisão no momento do treinamento e produzindo a classe que é a moda (valor mais frequente) das classes (classificação) ou predição média (regressão) das árvores individuais. RandomForest pertence à categoria dos métodos de ensemble, especificamente aos métodos de bagging, onde múltiplos modelos são treinados para resolver o mesmo problema e, em seguida, a média ou a votação majoritária de seus resultados é usada para obter uma previsão mais precisa. Funcionamento Básico do RandomForest:\n",
    "\n",
    "**Seleção Aleatória de Amostras:** Para cada árvore individual, uma amostra aleatória de dados é selecionada do conjunto de treinamento. Este processo é conhecido como bootstrap sampling, que permite que algumas observações sejam selecionadas várias vezes para uma mesma árvore, enquanto outras podem ser deixadas de fora.\n",
    "\n",
    "**Construção de Árvores de Decisão:** Cada árvore é construída de maneira a crescer ao máximo, com um twist: em cada divisão (ou nó), em vez de procurar a melhor característica entre todas as características disponíveis, o algoritmo busca a melhor característica entre um subconjunto aleatório das características. Isso aumenta a diversidade entre as árvores, o que ajuda a melhorar a robustez do modelo.\n",
    "\n",
    "**Predição:** Para fazer previsões, o RandomForest utiliza todas as árvores individualmente construídas. No caso de problemas de classificação, a previsão final é feita por votação majoritária, ou seja, a classe mais frequente entre todas as árvores é escolhida como a previsão final. Para problemas de regressão, a média das previsões de todas as árvores é calculada para obter a previsão final.\n",
    "\n",
    "**Vantagens**\n",
    "* Robustex, como é contruído a partir de múltiplas árvores, é menos propenso a overfitting do que uma única árvore de decisão.\n",
    "* Flexibilidade, pode ser usado tanto para tarefas de classificação quanto de regressão\n",
    "* Fácil de usar, requer pouca preparação dos dados, por exemplo, não é necessário escalar as características.\n",
    "* Importância das caracteristicas, pode forneceder insights sobre quais características são mais importantes para a previsão\n",
    "\n",
    "**Desvantagens**\n",
    "* Complexidade e Tempo de Treinamento, como constrói muitas árvores, pode ser computacionalmente intensivo e lento para treinar, especialmente com grandes volumes de dados.\n",
    "* Interpretabilidade, embora seja mais interpretável do que alguns modelos de aprendizado de máquina, ainda é mais dificil de interpretar do que uma árovere de decisão única devido à sua natureza de ensemble.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Random Forest Classifier:\n",
      "\n",
      "Treinamento:\n",
      "\n",
      "AUC:1.000\n",
      "Acurácia:1.000\n",
      "Recall:1.000\n",
      "Precisão:1.000\n",
      "Especificidade:1.000\n",
      " \n",
      "Validação:\n",
      "\n",
      "AUC:0.994\n",
      "Acurácia:0.957\n",
      "Recall:0.963\n",
      "Precisão:0.844\n",
      "Especificidade:0.954\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Cria o classificador com RandomForest\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Treina e cria o modelo\n",
    "modelo_v5 = rfc.fit(X_treino_tf, y_treino)\n",
    "\n",
    "# Previsões\n",
    "y_train_preds = modelo_v5.predict_proba(X_treino_tf)[:,1]\n",
    "y_valid_preds = modelo_v5.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Modelo Random Forest Classifier:\\n')\n",
    "\n",
    "print('Treinamento:\\n')\n",
    "rfc_train_auc, rfc_train_accuracy, rfc_train_recall, rfc_train_precision, rfc_train_specificity = dsa_print_report(y_treino, \n",
    "                                                                                                                   y_train_preds, \n",
    "                                                                                                                   thresh)\n",
    "\n",
    "print('Validação:\\n')\n",
    "rfc_valid_auc, rfc_valid_accuracy, rfc_valid_recall, rfc_valid_precision, rfc_valid_specificity = dsa_print_report(y_valid, \n",
    "                                                                                                                   y_valid_preds, \n",
    "                                                                                                                   thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classificador</th>\n",
       "      <th>data_set</th>\n",
       "      <th>auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL1</td>\n",
       "      <td>treino</td>\n",
       "      <td>0.627307</td>\n",
       "      <td>0.660471</td>\n",
       "      <td>0.530979</td>\n",
       "      <td>0.716555</td>\n",
       "      <td>0.789963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL1</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.524777</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.324752</td>\n",
       "      <td>0.752360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RL2</td>\n",
       "      <td>treino</td>\n",
       "      <td>0.630225</td>\n",
       "      <td>0.662639</td>\n",
       "      <td>0.531599</td>\n",
       "      <td>0.720403</td>\n",
       "      <td>0.793680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL2</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.524754</td>\n",
       "      <td>0.700870</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.761801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB</td>\n",
       "      <td>treino</td>\n",
       "      <td>0.982899</td>\n",
       "      <td>0.927200</td>\n",
       "      <td>0.884139</td>\n",
       "      <td>0.967458</td>\n",
       "      <td>0.970260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.984406</td>\n",
       "      <td>0.955362</td>\n",
       "      <td>0.864943</td>\n",
       "      <td>0.909366</td>\n",
       "      <td>0.978214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB</td>\n",
       "      <td>treino</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGB</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.900826</td>\n",
       "      <td>0.973856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RFC</td>\n",
       "      <td>treino</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RFC</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.994288</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.843829</td>\n",
       "      <td>0.954248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classificador data_set       auc  accuracy    recall  precision  specificity\n",
       "0           RL1   treino  0.627307  0.660471  0.530979   0.716555     0.789963\n",
       "1           RL1    valid  0.524777  0.695652  0.471264   0.324752     0.752360\n",
       "2           RL2   treino  0.630225  0.662639  0.531599   0.720403     0.793680\n",
       "3           RL2    valid  0.524754  0.700870  0.459770   0.327869     0.761801\n",
       "4            NB   treino  0.982899  0.927200  0.884139   0.967458     0.970260\n",
       "5            NB    valid  0.984406  0.955362  0.864943   0.909366     0.978214\n",
       "6           XGB   treino  1.000000  1.000000  1.000000   1.000000     1.000000\n",
       "7           XGB    valid  0.993439  0.966957  0.939655   0.900826     0.973856\n",
       "8           RFC   treino  1.000000  1.000000  1.000000   1.000000     1.000000\n",
       "9           RFC    valid  0.994288  0.956522  0.962644   0.843829     0.954248"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela de resultados\n",
    "df_results = pd.DataFrame({'classificador':['RL1', 'RL1', 'RL2', 'RL2', 'NB', 'NB', 'XGB', 'XGB', 'RFC', 'RFC'],\n",
    "                           'data_set':['treino','valid'] * 5,\n",
    "                           'auc':[lr1_train_auc,\n",
    "                                  lr1_valid_auc,\n",
    "                                  lr2_train_auc,\n",
    "                                  lr2_valid_auc,\n",
    "                                  nb_train_auc,\n",
    "                                  nb_valid_auc,\n",
    "                                  xgbc_train_auc,\n",
    "                                  xgbc_valid_auc,\n",
    "                                  rfc_train_auc,\n",
    "                                  rfc_valid_auc],\n",
    "                           'accuracy':[lr1_train_accuracy,\n",
    "                                       lr1_valid_accuracy,\n",
    "                                       lr2_train_accuracy,\n",
    "                                       lr2_valid_accuracy,\n",
    "                                       nb_train_accuracy,\n",
    "                                       nb_valid_accuracy,\n",
    "                                       xgbc_train_accuracy,\n",
    "                                       xgbc_valid_accuracy,\n",
    "                                       rfc_train_accuracy,\n",
    "                                       rfc_valid_accuracy],\n",
    "                           'recall':[lr1_train_recall,\n",
    "                                     lr1_valid_recall,\n",
    "                                     lr2_train_recall,\n",
    "                                     lr2_valid_recall,\n",
    "                                     nb_train_recall,\n",
    "                                     nb_valid_recall,\n",
    "                                     xgbc_train_recall,\n",
    "                                     xgbc_valid_recall,\n",
    "                                     rfc_train_recall,\n",
    "                                     rfc_valid_recall],\n",
    "                           'precision':[lr1_train_precision,\n",
    "                                        lr1_valid_precision,\n",
    "                                        lr2_train_precision,\n",
    "                                        lr2_valid_precision,\n",
    "                                        nb_train_precision,\n",
    "                                        nb_valid_precision,\n",
    "                                        xgbc_train_precision,\n",
    "                                        xgbc_valid_precision,\n",
    "                                        rfc_train_precision,\n",
    "                                        rfc_valid_precision],\n",
    "                           'specificity':[lr1_train_specificity,\n",
    "                                          lr1_valid_specificity,\n",
    "                                          lr2_train_specificity,\n",
    "                                          lr2_valid_specificity,\n",
    "                                          nb_train_specificity,\n",
    "                                          nb_valid_specificity,\n",
    "                                          xgbc_train_specificity,\n",
    "                                          xgbc_valid_specificity,\n",
    "                                          rfc_train_specificity,\n",
    "                                          rfc_valid_specificity]})\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classificador</th>\n",
       "      <th>data_set</th>\n",
       "      <th>auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RFC</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.994288</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.843829</td>\n",
       "      <td>0.954248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGB</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.900826</td>\n",
       "      <td>0.973856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.984406</td>\n",
       "      <td>0.955362</td>\n",
       "      <td>0.864943</td>\n",
       "      <td>0.909366</td>\n",
       "      <td>0.978214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL1</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.524777</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.324752</td>\n",
       "      <td>0.752360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL2</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.524754</td>\n",
       "      <td>0.700870</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.761801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classificador data_set       auc  accuracy    recall  precision  specificity\n",
       "9           RFC    valid  0.994288  0.956522  0.962644   0.843829     0.954248\n",
       "7           XGB    valid  0.993439  0.966957  0.939655   0.900826     0.973856\n",
       "5            NB    valid  0.984406  0.955362  0.864943   0.909366     0.978214\n",
       "1           RL1    valid  0.524777  0.695652  0.471264   0.324752     0.752360\n",
       "3           RL2    valid  0.524754  0.700870  0.459770   0.327869     0.761801"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultados em validação com ordenação pelo AUC\n",
    "df_results[df_results['data_set'] == 'valid'].sort_values(by = 'auc', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A métrica de desempenho escolhida será a pontuação AUC (AUC Score) do conjunto de validação. É a pontuação mais comum usada para comparar modelos de algoritmos diferentes. Acuracia é ideal para quando é comparado modelos do mesmo algoritimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (16, 8))\n",
    "ax = sns.barplot(x = 'classificador', y = 'auc', hue = 'data_set', data = df_results)\n",
    "ax.set_xlabel('Classificador', fontsize = 15)\n",
    "ax.set_ylabel('AUC', fontsize = 15)\n",
    "ax.tick_params(labelsize = 15)\n",
    "plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad = 0., fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de Hiperparâmetros e Validação Cruzada\n",
    "\n",
    "A otimização de hiperparâmetros e a validação cruzada são técnicas fundamentais em aprendizado de máquina, usadas para melhorar o desempenho dos modelos e garantir que eles generalizem bem para dados não vistos. Hiperparâmetros são os parâmetros de configuração do modelo que precisam ser definidos antes do treinamento do modelo e que não são aprendidos a partir dos dados. Eles têm um grande impacto no desempenho do modelo. A otimização de hiperparâmetros é o processo de buscar a melhor combinação de hiperparâmetros que resulta no melhor desempenho do modelo para uma tarefa específica. Diferentes métodos podem ser usados para a otimização de hiperparâmetros, incluindo:\n",
    "* **Grid Search**: Um método exaustivo que testa todas as combinações possíveis de hiperparâmetros dentro de um espaço de busca definido. Método usado neste capítulo.\n",
    "* **Random Search**: Seleciona aleatoriamente combinações de hiperparâmetros para testar, o que pode ser mais eficiente que o Grid Search em espaços de busca grandes.\n",
    "* **Otimização Bayesiana**: Utiliza modelos probabilísticos para prever quais combinações de hiperparâmetros podem resultar em melhor desempenho, focando a busca nessas áreas promissoras.\n",
    "* **Algoritmos Genéticos e Outras Heurísticas**: Abordagens inspiradas na natureza que simulam a evolução para encontrar as melhores combinações de hiperparâmetros.\n",
    "\n",
    "### Validação Cruzada\n",
    "A validação cruzada é uma técnica de avaliação de modelos usada para estimar a habilidade de generalização de um modelo em dados não vistos. Isso é importante para evitar o problema de overfitting, onde o modelo se ajusta muito bem aos dados de treinamento mas falha em prever novos dados com precisão. A validação cruzada mais comum é a k-fold:\n",
    "* O conjunto de dados é dividido aleatoriamente em k subconjuntos (ou \"folds\").\n",
    "* O modelo é treinado k vezes, cada vez usando k-1 folds para treinamento e o fold restante para teste.\n",
    "* O desempenho do modelo é então avaliado usando uma métrica específica, como precisão ou erro quadrático médio, e os resultados são médios para obter uma estimativa geral do desempenho do modelo.\n",
    "A validação cruzada garante que cada observação dos dados seja usada para treinamento e teste exatamente uma vez, proporcionando uma avaliação robusta do desempenho do modelo. Juntas, a otimização de hiperâmetros e a validação cruzada formam um processo poderoso para desenvolver modelos de aprendizado de máquina. A otimização ajusta o modelo para alcançar o melhor desempenho possível, enquanto a validação cruzada assegura que este desempenho é realista e que o modelo é capaz de generalizar além dos dados de treinamento. Essas técnicas ajudam a maximizar a eficácia dos modelos de aprendizado de máquina em resolver problemas do mundo real.\n",
    "\n",
    "\n",
    "Para incluir a otimização de hiperparâmetros e a validação cruzada no projeto, você pode usar o GridSearchCV do scikit-learn, que permite buscar a melhor combinação de hiperparâmetros para o modelo. Vamos usar o RandomForest como modelo base.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   5.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   5.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   5.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   5.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   7.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.8s\n",
      "Melhores hiperparâmetros: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Modelo Random Forest Classifier com Otimização de Hiperparâmetros e Validação Cruzada:\n",
      "\n",
      "Treinamento:\n",
      "\n",
      "AUC:1.000\n",
      "Acurácia:1.000\n",
      "Recall:1.000\n",
      "Precisão:1.000\n",
      "Especificidade:1.000\n",
      " \n",
      "Validação:\n",
      "\n",
      "AUC:0.994\n",
      "Acurácia:0.959\n",
      "Recall:0.974\n",
      "Precisão:0.845\n",
      "Especificidade:0.955\n",
      " \n",
      "CPU times: user 6.75 s, sys: 333 ms, total: 7.09 s\n",
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Importa a função GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Defina o espaço de busca dos hiperparâmetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Cria o classificador com RandomForest\n",
    "classificador = RandomForestClassifier()\n",
    "\n",
    "# Configura o GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classificador, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 5, \n",
    "                           scoring = 'roc_auc', \n",
    "                           verbose = 2, \n",
    "                           n_jobs = -1)\n",
    "\n",
    "# Treina o modelo com validação cruzada e busca pelos melhores hiperparâmetros\n",
    "modelo_v5_otimizado = grid_search.fit(X_treino_tf, y_treino)\n",
    "\n",
    "# Melhores hiperparâmetros encontrados\n",
    "print('Melhores hiperparâmetros:', modelo_v5_otimizado.best_params_)\n",
    "\n",
    "# Previsões\n",
    "y_train_preds = modelo_v5_otimizado.predict_proba(X_treino_tf)[:,1]\n",
    "y_valid_preds = modelo_v5_otimizado.predict_proba(X_valid_tf)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Random Forest Classifier com Otimização de Hiperparâmetros e Validação Cruzada:\n",
      "\n",
      "Treinamento:\n",
      "\n",
      "AUC:1.000\n",
      "Acurácia:1.000\n",
      "Recall:1.000\n",
      "Precisão:1.000\n",
      "Especificidade:1.000\n",
      " \n",
      "Validação:\n",
      "\n",
      "AUC:0.994\n",
      "Acurácia:0.959\n",
      "Recall:0.974\n",
      "Precisão:0.845\n",
      "Especificidade:0.955\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('Modelo Random Forest Classifier com Otimização de Hiperparâmetros e Validação Cruzada:\\n')\n",
    "\n",
    "print('Treinamento:\\n')\n",
    "rfc_train_auc, rfc_train_accuracy, rfc_train_recall, rfc_train_precision, rfc_train_specificity = dsa_print_report(y_treino, \n",
    "                                                                                                                   y_train_preds, \n",
    "                                                                                                                   thresh)\n",
    "\n",
    "print('Validação:\\n')\n",
    "rfc_valid_auc, rfc_valid_accuracy, rfc_valid_recall, rfc_valid_precision, rfc_valid_specificity = dsa_print_report(y_valid, \n",
    "                                                                                                                   y_valid_preds, \n",
    "                                                                                                                   thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qual Versão Final Devemos Usar? Justifique Sua Resposta!\n",
    "\n",
    "Modelo RandomForest \"Vanilla\":\n",
    "\n",
    "Validação:\n",
    "\n",
    "AUC:0.994\n",
    "Acurácia:0.957\n",
    "Recall:0.963\n",
    "Precisão:0.844\n",
    "Especificidade:0.954\n",
    " \n",
    "\n",
    "Modelo RandomForest Otimizado:\n",
    "\n",
    "Validação:\n",
    "\n",
    "AUC:0.994\n",
    "Acurácia:0.959\n",
    "Recall:0.974\n",
    "Precisão:0.845\n",
    "Especificidade:0.955\n",
    "\n",
    "Ambos os modelos com RandomForest apresentam desempenho muito alto, mas há algumas nuances a serem consideradas ao escolher qual deles usar:\n",
    "\n",
    "**Desempenho na validação**: O modelo com otimização de hiperparâmetros tem uma AUC ligeiramente maior na validação, o que indica que ele pode generalizar um pouco melhor. No entanto, outras métricas são um pouco menores nesse modelo. Essas diferenças são pequenas e podem não ser significativas, dependendo do contexto e da importância relativa dessas métricas para o seu problema específico.\n",
    "\n",
    "**Complexidade e tempo de treinamento**: A otimização de hiperparâmetros aumenta a complexidade do processo de treinamento e o tempo necessário para treinar o modelo. Se o tempo de treinamento for uma preocupação e as diferenças de desempenho forem consideradas insignificantes, você pode optar pelo modelo sem otimização de hiperparâmetros.\n",
    "\n",
    "Se você estiver preocupado com o overfitting e quiser um modelo que possa generalizar um pouco melhor para novos dados, o modelo com otimização de hiperparâmetros pode ser a melhor escolha, apesar de seu desempenho ligeiramente inferior na validação em algumas métricas. No entanto, se o tempo de treinamento for uma preocupação e as diferenças de desempenho forem aceitáveis para o seu caso de uso, o modelo sem otimização de hiperparâmetros pode ser suficiente.\n",
    "\n",
    "Decisão: Usaremos o modelo RandomForest sem otimização de hiperparâmetros pois é mais simples e requer menos tempo de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o Melhor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava o modelo em disco\n",
    "pickle.dump(modelo_v5, open('models/melhor_modelo.pkl', 'wb'), protocol = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vamos fazer a avaliação final do melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo, as colunas e o scaler\n",
    "best_model = pickle.load(open('models/melhor_modelo.pkl','rb'))\n",
    "cols_input = pickle.load(open('data/colunas_entrada.sav','rb'))\n",
    "scaler = pickle.load(open('data/scaler.sav', 'rb'))\n",
    "\n",
    "# Carrega os dados\n",
    "df_train = pd.read_csv('data/dados_treino_final.csv')\n",
    "df_valid = pd.read_csv('data/dados_valid.csv')\n",
    "df_test = pd.read_csv('data/dados_teste.csv')\n",
    "\n",
    "# Cria matrizes x e y\n",
    "\n",
    "# X\n",
    "X_train = df_train[cols_input].values\n",
    "X_valid = df_valid[cols_input].values\n",
    "X_test = df_test[cols_input].values\n",
    "\n",
    "# Y\n",
    "y_train = df_train['LABEL_TARGET'].values\n",
    "y_valid = df_valid['LABEL_TARGET'].values\n",
    "y_test = df_test['LABEL_TARGET'].values\n",
    "\n",
    "# Aplica a transformação nos dados\n",
    "X_train_tf = scaler.transform(X_train)\n",
    "X_valid_tf = scaler.transform(X_valid)\n",
    "X_test_tf = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões de probabilidade\n",
    "y_train_preds = best_model.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = best_model.predict_proba(X_valid_tf)[:,1]\n",
    "y_test_preds = best_model.predict_proba(X_test_tf)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Avaliação final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinamento:\n",
      "\n",
      "AUC:1.000\n",
      "Acurácia:1.000\n",
      "Recall:1.000\n",
      "Precisão:1.000\n",
      "Especificidade:1.000\n",
      " \n",
      "\n",
      "Validação:\n",
      "\n",
      "AUC:0.994\n",
      "Acurácia:0.957\n",
      "Recall:0.963\n",
      "Precisão:0.844\n",
      "Especificidade:0.954\n",
      " \n",
      "\n",
      "Teste:\n",
      "\n",
      "AUC:0.994\n",
      "Acurácia:0.955\n",
      "Recall:0.982\n",
      "Precisão:0.824\n",
      "Especificidade:0.947\n",
      " \n"
     ]
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "\n",
    "print('\\nTreinamento:\\n')\n",
    "train_auc, train_accuracy, train_recall, train_precision, train_specificity = dsa_print_report(y_train,\n",
    "                                                                                               y_train_preds, \n",
    "                                                                                               thresh)\n",
    "\n",
    "print('\\nValidação:\\n')\n",
    "valid_auc, valid_accuracy, valid_recall, valid_precision, valid_specificity = dsa_print_report(y_valid,\n",
    "                                                                                               y_valid_preds, \n",
    "                                                                                               thresh)\n",
    "\n",
    "print('\\nTeste:\\n')\n",
    "test_auc, test_accuracy, test_recall, test_precision, test_specificity = dsa_print_report(y_test,\n",
    "                                                                                          y_test_preds, \n",
    "                                                                                          thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcula a curva ROC nos dados de treino\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_preds)\n",
    "auc_train = roc_auc_score(y_train, y_train_preds)\n",
    "\n",
    "# Calcula a curva ROC nos dados de validação\n",
    "fpr_valid, tpr_valid, thresholds_valid = roc_curve(y_valid, y_valid_preds)\n",
    "auc_valid = roc_auc_score(y_valid, y_valid_preds)\n",
    "\n",
    "# Calcula a curva ROC nos dados de teste\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_preds)\n",
    "auc_test = roc_auc_score(y_test, y_test_preds)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(fpr_train, tpr_train, 'r-', label = 'AUC em Treino: %.3f'%auc_train)\n",
    "plt.plot(fpr_valid, tpr_valid, 'b-', label = 'AUC em Validação: %.3f'%auc_valid)\n",
    "plt.plot(fpr_test, tpr_test, 'g-', label = 'AUC em Teste: %.3f'%auc_test)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X169</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>-41</td>\n",
       "      <td>-16</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...  X169  X170  X171  X172  X173  \\\n",
       "0  42  53  44  31  15  12   6   4   1   -4  ...   -41   -16     2    22    33   \n",
       "\n",
       "   X174  X175  X176  X177  X178  \n",
       "0    45    56    67    69    63  \n",
       "\n",
       "[1 rows x 178 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando dados de um novo cliente\n",
    "novo_cliente = pd.read_csv('data/novo_cliente.csv')\n",
    "novo_cliente.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_cliente_scaled = scaler.transform(novo_cliente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba(novo_cliente_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(novo_cliente_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
